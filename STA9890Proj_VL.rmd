---
title: "9890 Final Project"
author: "Mamadou Sow, Victor Lazarte, Ella Shafi"
date: "`r Sys.Date()`"
output:
  beamer_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r load results, include=FALSE}
library(tidyverse)
library(modelr)
library(glmnet)
library(glmnetUtils)
library(MASS)
library(tree)
library(randomForest)
library(knitr)

load("allresults.RData")
```
## Part 4(b) Data Description

* The Insurance Company Benchmark data set contains information on customers of an insurance company. 

* The main goal of the project is to assess the number of mobile home policies per customer.

* The data consists of 86 variables, from which, 5 are categorical and the 81 of them are numerical predictors.

* The response variable is Caravans (the 86th variable in dataset), or the number of mobile home policies.

* The predictor variables are socioeconomic variables such as average size of household and product ownership variables such as contribution boat policies. 

* From 5588 responses, %80 of the data (4657 observations) was used as training set and 930 variables as test set.

## Part 4(b) Boxplots

* From lasso, ridge and random forest regression methods, the R squared for both train and test samples are calculated.
As we can see, for both test and train sets the R2 value of ridge and lasso are quite close while random forest has a relatively higher value. 

```{r box plots, fig.height=5, message=FALSE, warning=FALSE, paged.print=FALSE}
par(mfrow=c(1, 2))
boxplot(Rsq.train ~ Model, data=b, xlab="Train", ylab="R squared")
boxplot(Rsq.test ~ Model, data=b, xlab="Test", ylab="")

```

## Part 4 (c) - Time Logs

```{r time, fig.height=3, fig.width=6}
knitr::kable(time.tab, col.names = c("Method", "Run Time"), format = "pipe")

```

## Part 5

* Based on the following analysis, we see that there is indeed a trade off between the time it takes to train the model and predictive performance. This is in line with our expectations that higher predictive performance requires additional computing power and by extension time for the system to run.

## Part 5 - CI Plots
```{r CIplots, fig.height=4, fig.width=7}
par(mfrow=c(1, 2))
plot(cv.fit.ridge)
plot(cv.fit.ls)

```

## Time Table
```{r table, message=FALSE, warning=FALSE, paged.print=FALSE}
## Part 5
knitr::kable(result.table, col.names = c("Method", "CI %90 LB", "CI %90 UB", "Full Run Time"))

```



